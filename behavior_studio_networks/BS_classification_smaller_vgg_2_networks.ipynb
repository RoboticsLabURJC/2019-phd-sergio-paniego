{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BS_classification_smaller_vgg_2_networks.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1IZrnJzFUg70xh7ShLznXx2BKgraPqqn-","authorship_tag":"ABX9TyONSBGonvuheoD/HnyGIdCN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r9lybteka4VI"},"source":["<a href=\"https://colab.research.google.com/github/RoboticsLabURJC/2019-phd-sergio-paniego/blob/main/behavior_studio_networks/BS_classification_smaller_vgg_2_networks.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"]},{"cell_type":"code","metadata":{"id":"46DR5IVkAPmM"},"source":["# Mount Google Drive to access images dataset\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPtqkrfFX8Pl"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import backend as K\n","\n","from keras.utils import plot_model, np_utils\n","import numpy as np\n","import glob\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import TensorBoard, CSVLogger, ModelCheckpoint\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","\n","from time import time\n","\n","def SmallerVGGNet(input_shape, num_classes):\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n","    model.add(Activation('relu'))\n","    model.add(BatchNormalization(axis=-1))\n","    model.add(MaxPooling2D(pool_size=(3, 3)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(64, (3, 3), padding='same'))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=-1))\n","    model.add(Conv2D(64, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(BatchNormalization(axis=-1))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(128, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(BatchNormalization(axis=-1))\n","    model.add(Conv2D(128, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(BatchNormalization(axis=-1))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Flatten())\n","    model.add(Dense(1024))\n","    model.add(Activation('relu'))\n","    model.add(BatchNormalization(axis=-1))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Dense(units=num_classes, activation='sigmoid'))\n","\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return model\n","\n","def get_images(list_images, type_image):\n","    # Read the images\n","    array_imgs = []\n","    for name in list_images:\n","        img = cv2.imread(name)\n","        if type_image == 'cropped':\n","            img = img[240:480, 0:640]\n","        img = cv2.resize(img, (int(img.shape[1] / 4), int(img.shape[0] / 4)))\n","        array_imgs.append(img)\n","\n","    return array_imgs\n","\n","def parse_json_7_classes_w(data):\n","    # Process json 7 classes for w\n","    array_class = []\n","    array_w = []\n","    data_parse = data.split('\"class2\": ')[1:]\n","    for d in data_parse:\n","        classification = d.split(', \"class3\":')[0]\n","        d_parse = d.split(', \"w\": ')[1]\n","        w = float(d_parse.split(', \"v\":')[0])\n","        array_class.append(classification)\n","        array_w.append(w)\n","\n","    return array_class, array_w\n","\n","def parse_json_4_classes_v(data):\n","    # Process json 54 classes for v\n","    array_class = []\n","    array_w = []\n","    data_parse = data.split('\"class3\": ')[1:]\n","    for d in data_parse:\n","        classification = d.split(', \"w\":')[0]\n","        d_parse = d.split(', \"w\": ')[1]\n","        w = float(d_parse.split(', \"v\":')[0])\n","        array_class.append(classification)\n","        array_w.append(w)\n","\n","    return array_class, array_w\n","\n","def parse_json_5_classes_v(data):\n","    # Process json 5 classes for v\n","    array_class = []\n","    array_w = []\n","    data_parse = data.split('\"class_v_5\": ')[1:]\n","    for d in data_parse:\n","        classification = d.split(', \"class_w_9\":')[0]\n","        d_parse = d.split(', \"w\": ')[1]\n","        w = float(d_parse.split(', \"v\":')[0])\n","        array_class.append(classification)\n","        array_w.append(w)\n","\n","    return array_class, array_w\n","\n","def remove_values_aprox_zero(list_imgs, list_data, list_w):\n","    index = [i for i,x in enumerate(list_w) if np.isclose([x], [0.0], atol=0.08)[0] == True]\n","    for i in range(len(index)-1, 0, -1):\n","        list_data.pop(index[i])\n","        list_imgs.pop(index[i])\n","    return list_imgs, list_data\n","\n","\n","def parse_json(data, num_classes, name_variable):\n","    if num_classes == 7 and name_variable == 'w':\n","        array_class, array_w = parse_json_7_classes_w(data)\n","    elif num_classes == 4 and name_variable == 'v':\n","        array_class, array_w = parse_json_4_classes_v(data)\n","    elif num_classes == 5 and name_variable == 'v':\n","        array_class, array_w = parse_json_5_classes_v(data)\n","    return array_class, array_w\n","\n","def adapt_label_7_w(label):\n","    if label == '\"radically_left\"' or label == 'radically_left':\n","        label = 0\n","    elif label == '\"moderately_left\"' or label == 'moderately_left':\n","        label = 1\n","    elif label == '\"slightly_left\"' or label == 'slightly_left':\n","        label = 2\n","    elif label == '\"slight\"' or label == 'slight':\n","        label = 3\n","    elif label == '\"slightly_right\"' or label == 'slightly_right':\n","        label = 4\n","    elif label == '\"moderately_right\"' or label == 'moderately_right':\n","        label = 5\n","    elif label == '\"radically_right\"' or label == 'radically_right':\n","        label = 6\n","    return label\n","\n","\n","def adapt_label_4_v(label):\n","    if label == '\"slow\"' or label == 'slow':\n","        label = 0\n","    elif label == '\"moderate\"' or label == 'moderate':\n","        label = 1\n","    elif label == '\"fast\"' or label == 'fast':\n","        label = 2\n","    elif label == '\"very_fast\"' or label == 'very_fast':\n","        label = 3\n","    return label\n","\n","\n","def adapt_label_5_v(label):\n","    if label == '\"slow\"' or label == 'slow':\n","        label = 0\n","    elif label == '\"moderate\"' or label == 'moderate':\n","        label = 1\n","    elif label == '\"fast\"' or label == 'fast':\n","        label = 2\n","    elif label == '\"very_fast\"' or label == 'very_fast':\n","        label = 3\n","    elif label == '\"negative\"' or label == 'negative':\n","        label = 4\n","    return label\n","\n","\n","def adapt_labels(array_labels, num_classes, name_variable):\n","    for i in range(0, len(array_labels)):\n","        if name_variable == 'w':\n","            if num_classes == 7:\n","                array_labels[i] = adapt_label_7_w(array_labels[i])\n","        elif name_variable == 'v':\n","            if num_classes == 4:\n","                array_labels[i] = adapt_label_4_v(array_labels[i])\n","            elif num_classes == 5:\n","                array_labels[i] = adapt_label_5_v(array_labels[i])\n","    return array_labels\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7xWfRpqpd6R"},"source":["!ls \"/content/drive/My Drive\"\n","!ls \"/content/drive/My Drive/complete_dataset.zip\"\n","!unzip \"/content/drive/My Drive/curves_only.zip\"\n","!unzip \"/content/drive/My Drive/complete_dataset.zip\"\n","\n","\n","import os \n","#directory = os.listdir(\"/content/curves_only/Images\")\n","#directory = os.listdir(\"/content/complete_dataset/Images\")\n","#directory = os.listdir(\"/content/complete_dataset/Train_balanced_bbdd_v/Images\")\n","#directory = os.listdir(\"/content/complete_dataset/Train_balanced_bbdd_w/Images\")\n","directory = os.listdir(\"/content/complete_dataset/Train/Images\")\n","\n","import cv2\n","#img = cv2.imread(\"/content/curves_only/Images/4143.png\")\n","#img = cv2.imread(\"/content/complete_dataset/Images/4143.png\")\n","#img = cv2.imread(\"/content/complete_dataset/Train_balanced_bbdd_v/Images/4143.png\")\n","#img = cv2.imread(\"/content/complete_dataset/Train_balanced_bbdd_w/Images/1363.png\")\n","img = cv2.imread(\"/content/complete_dataset/Train/Images/4143.png\")\n","height, width, channels = img.shape\n","# CHANGE num_classes\n","#num_classes = 7\n","#num_classes = 4\n","num_classes = 5\n","\n","\n","#list_images = glob.glob('/content/curves_only/Images/' + '*')\n","#list_images = glob.glob('/content/complete_dataset/Images/' + '*')\n","#list_images = glob.glob('/content/complete_dataset/Train_balanced_bbdd_v/Images/' + '*')\n","#list_images = glob.glob('/content/complete_dataset/Train_balanced_bbdd_w/Images/' + '*')\n","list_images = glob.glob('/content/complete_dataset/Train/Images/' + '*')\n","\n","\n","images = sorted(list_images, key=lambda x: int(x.split('/')[5].split('.png')[0]))\n","\n","#file = open('/content/curves_only/data.json', 'r')\n","#file = open('/content/complete_dataset/data.json', 'r')\n","#file = open('/content/complete_dataset/Train_balanced_bbdd_v/train.json', 'r')\n","#file = open('/content/complete_dataset/Train_balanced_bbdd_w/train.json', 'r')\n","file = open('/content/complete_dataset/Train/train.json', 'r')\n","\n","data = file.read()\n","file.close()\n","# CHANGE type_image\n","type_image = 'cropped'\n","#type_image='normal'\n","\n","# CHANGE name_variable between v and w to generate the output for that specific\n","#name_variable='w'\n","name_variable='v'\n","\n","print('----- LOADING DATASET ----')\n","x = get_images(images, type_image)\n","# Preprocess json\n","y, array_w = parse_json(data, num_classes, name_variable)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jqZOiRzrpsBH"},"source":["print(img.shape)\n","if type_image == 'cropped':\n","    img_shape = (60, 160, 3)\n","else:\n","    img_shape = (120, 160, 3)\n","#img_shape = (120, 160, 3)\n","print(num_classes)\n","model = SmallerVGGNet(img_shape, num_classes)\n","print(model)\n","\n","# We delete values close to zero\n","x_train, y_train = remove_values_aprox_zero(x, y, array_w)\n","#x_train = x\n","#y_train = y\n","\n","y_train = adapt_labels(y_train, num_classes, name_variable)\n","\n","\n","# CHANGE type_net\n","# BALANCED DATASET OR NOT??\n","#type_net = 'balanced'\n","type_net = 'biased'\n","\n","\n","\n","if type_net == 'balanced':\n","  X_train = x_train\n","  y_train = y_train\n","  X_t, X_validation, y_t, y_validation = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n","else:\n","  X_train, X_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.20,\n","                                                                random_state=42)\n","\n","\n","# CHANGE batch_size\n","# CHANGE nb_epochs\n","batch_size = 64\n","# nb_epochs = 10\n","nb_epochs = 65\n","\n","y_train = np_utils.to_categorical(y_train, num_classes)\n","y_validation = np_utils.to_categorical(y_validation, num_classes)\n","\n","X_train = np.stack(X_train, axis=0)\n","y_train = np.stack(y_train, axis=0)\n","X_validation = np.stack(X_validation, axis=0)\n","y_validation = np.stack(y_validation, axis=0)\n","\n","# CHANGE class_weight\n","if type_net == \"biased\" and num_classes == 7:\n","    nb_epochs = 55\n","    class_weight = {0: 4., 1: 2., 2: 2., 3: 1., 4:2., 5: 2., 6: 3.}\n","elif type_net == \"biased\" and num_classes == 5:\n","    class_weight = {0: 2., 1: 3., 2: 3., 3: 4., 4: 15}\n","elif type_net == \"biased\" and num_classes == 4:\n","    class_weight = {0: 2., 1: 3., 2: 3., 3: 4.}\n","else:\n","    class_weight = None\n","\n","# Print layers\n","print(model.summary())\n","\n","tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n","\n","name_model='smaller_vgg'\n","#normal='normal'\n","#type_net = 'normal'\n","\n","#  Train\n","model_history = model.fit(X_train, y_train, epochs=nb_epochs, batch_size=batch_size, verbose=2,\n","                          class_weight=class_weight, validation_data=(X_validation, y_validation),\n","                          callbacks=[tensorboard])\n","\n","\n","# Evaluate\n","score = model.evaluate(X_validation, y_validation, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","\n","# CHANGE Save model\n","#model_file = '/content/drive/My Drive/test_model_tf_keras_' + name_variable + '.h5'\n","#model_file = '/content/drive/My Drive/test_model_tf_keras_balanced_' + name_variable + '.h5'\n","model_file = '/content/drive/My Drive/test_model_tf_keras_cropped_' + type_net + '_' + name_variable + '.h5'\n","model.save(model_file)\n","\n","\n","print(model_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vFcxsjY4VYxG"},"source":["import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","# Loss Curves\n","plt.figure(figsize=[8, 6])\n","plt.plot(model_history.history['loss'], 'r', linewidth=3.0)\n","plt.plot(model_history.history['val_loss'], 'b', linewidth=3.0)\n","plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n","plt.xlabel('Epochs ', fontsize=16)\n","plt.ylabel('Loss', fontsize=16)\n","plt.title('Loss Curves', fontsize=16)\n","plt.show()\n","\n","# Accuracy Curves\n","plt.figure(figsize=[8, 6])\n","plt.plot(model_history.history['accuracy'], 'r', linewidth=3.0)\n","plt.plot(model_history.history['val_accuracy'], 'b', linewidth=3.0)\n","plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n","plt.xlabel('Epochs ', fontsize=16)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.title('Accuracy Curves', fontsize=16)\n","plt.show()"],"execution_count":null,"outputs":[]}]}