{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BS_lstm_tinypilotnet_1_network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRIBemSryaJ40DN2HvVf6Q"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xLrf-OB5dV-d"},"source":["<a href=\"https://colab.research.google.com/github/RoboticsLabURJC/2019-phd-sergio-paniego/blob/main/behavior_studio_networks/BS_lstm_tinypilotnet_1_network.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"]},{"cell_type":"code","metadata":{"id":"kXF_g0ZQclpc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8VzKqsJdaBn"},"source":["!ls \"/content/drive/My Drive\"\n","!ls \"/content/drive/My Drive/complete_dataset.zip\"\n","!unzip \"/content/drive/My Drive/curves_only.zip\"\n","!unzip \"/content/drive/My Drive/complete_dataset.zip\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D5g_Q8wJdbW1","executionInfo":{"status":"ok","timestamp":1603289113319,"user_tz":-120,"elapsed":2749,"user":{"displayName":"Sergio Paniego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieD7waLQfPmd1iQ_JxLD-xzFmWhCk91lg1cL71ic=s64","userId":"09118110808987317290"}}},"source":["from keras.models import Sequential\n","from keras.layers import Flatten,Dense,Conv2D,BatchNormalization,Dropout,ConvLSTM2D,Reshape,Activation,MaxPooling2D, LSTM, Input\n","from keras.layers.wrappers import TimeDistributed\n","from keras.optimizers import Adam\n","\n","\n","# LSTM tinypilotnet\n","def lstm_tinypilotnet_model(img_shape, type_image):\n","    model = Sequential()\n","    model.add(Conv2D(8, (3, 3), strides=(2, 2), input_shape=img_shape, activation=\"relu\"))\n","    model.add(Conv2D(16, (3, 3), strides=(2, 2), activation=\"relu\"))\n","    model.add(Conv2D(32, (3, 3), strides=(2, 2), activation=\"relu\"))\n","    if type_image == 'cropped':\n","        model.add(Reshape((1, 6, 19, 32)))\n","    else:\n","        model.add(Reshape((1, 14, 19, 32)))\n","\n","    model.add(ConvLSTM2D(filters=32, kernel_size=(3, 3), padding=\"same\", return_sequences=True, input_shape=img_shape))\n","    if type_image == 'cropped':\n","        model.add(Reshape((6, 19, 32)))\n","    else:\n","        model.add(Reshape((14, 19, 40)))\n","    model.add(Conv2D(1, (3, 3), strides=(2, 2), activation=\"relu\"))\n","    model.add(Flatten())\n","    model.add(Dense(2))\n","    adam = Adam(lr=0.0001)\n","    model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy', 'mse', 'mae'])\n","    return model\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-_CRTaLdhsp"},"source":["import glob\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","\n","\n","def load_data(folder):\n","    name_folder = '/content/' + folder + '/Images/'\n","    list_images = glob.glob(name_folder + '*')\n","    print(list_images)\n","    images = sorted(list_images, key=lambda x: int(x.split('/')[4].split('.png')[0]))\n","    name_file = '/content/' + folder + '/data.json'\n","    file = open(name_file, 'r')\n","    data = file.read()\n","    file.close()\n","    return images, data\n","\n","def get_images(list_images, type_image, array_imgs):\n","    # Read the images\n","    for name in list_images:\n","        img = cv2.imread(name)\n","        if type_image == 'cropped':\n","            img = img[240:480, 0:640]\n","        img = cv2.resize(img, (int(img.shape[1] / 4), int(img.shape[0] / 4)))\n","        array_imgs.append(img)\n","\n","    return array_imgs\n","\n","def parse_json(data, array):\n","    # Process json\n","    data_parse = data.split('}')[:-1]\n","    for d in data_parse:\n","        v = d.split('\"v\": ')[1]\n","        d_parse = d.split(', \"v\":')[0]\n","        w = d_parse.split(('\"w\": '))[1]\n","        array.append((float(v), float(w)))\n","\n","    return array\n","\n","def preprocess_data(array, imgs):\n","    # Data augmentation\n","    # Take the image and just flip it and negate the measurement\n","    flip_imgs = []\n","    array_flip = []\n","    for i in range(len(array)):\n","        flip_imgs.append(cv2.flip(imgs[i], 1))\n","        array_flip.append((array[i][0], -array[i][1]))\n","    new_array = array + array_flip\n","    new_array_imgs = imgs + flip_imgs\n","    return new_array, new_array_imgs\n","\n","def add_extreme_data(array, imgs):\n","    for i in range(0, len(array)):\n","        if abs(array[i][1]) >= 1:\n","            if abs(array[i][1]) >= 2:\n","                num_iter = 10\n","            else:\n","                num_iter = 5\n","            for j in range(0, num_iter):\n","                array.append(array[i])\n","                imgs.append(imgs[i])\n","        if float(array[i][0]) <= 2:\n","            for j in range(0, 1):\n","                array.append(array[i])\n","                imgs.append(imgs[i])\n","    return array, imgs\n","\n","\n","# Load data\n","images, data = load_data('complete_dataset')\n","images_curve, data_curve = load_data('curves_only')\n","\n","# CHANGE type_image\n","type_image = 'cropped'\n","#type_image='normal'\n","\n","# Preprocess images\n","array_imgs = []\n","array_imgs = get_images(images, type_image, array_imgs)\n","array_imgs = get_images(images_curve, type_image, array_imgs)\n","# Preprocess json\n","array_annotations = []\n","array_annotations = parse_json(data, array_annotations)\n","array_annotations = parse_json(data_curve, array_annotations)\n","\n","\n","if type_image == 'cropped':\n","    img_shape = (65, 160, 3)\n","else:\n","    img_shape = (120, 160, 3)\n","\n","\n","# Adapt the data\n","array_annotations, array_imgs = preprocess_data(array_annotations, array_imgs)\n","# x = x[:]\n","array_annotations, array_imgs = add_extreme_data(array_annotations, array_imgs)\n","images_train, images_validation, annotations_train, annotations_validation = train_test_split(array_imgs, array_annotations, test_size=0.20, random_state=42)\n","\n","\n","# Adapt the data\n","images_train = np.stack(images_train, axis=0)\n","annotations_train = np.stack(annotations_train, axis=0)\n","images_validation = np.stack(images_validation, axis=0)\n","annotations_validation = np.stack(annotations_validation, axis=0)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JqWg8lJdl1t","executionInfo":{"status":"error","timestamp":1603296788002,"user_tz":-120,"elapsed":3,"user":{"displayName":"Sergio Paniego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieD7waLQfPmd1iQ_JxLD-xzFmWhCk91lg1cL71ic=s64","userId":"09118110808987317290"}}},"source":["print(images_train[0].shape)\n","print(annotations_train[0])\n","print(img_shape)\n","img_shape = (60, 160, 3)\n","print(img_shape)\n","\n","model = lstm_tinypilotnet_model(img_shape, 'cropped')\n","batch_size = 64  # 16\n","nb_epoch = 25  # 223\n","\n","\n","if type_image == 'cropped':\n","    model_file = '/content/drive/My Drive/model_lstm_tinypilotnet_cropped_25.h5'\n","else:\n","    model_file = '/content/drive/My Drive/model_lstm_tinypilotnet_25.h5'\n","\n","# Print layers\n","print(model.summary())\n","\n","# Train\n","model_history = model.fit(images_train, annotations_train, epochs=nb_epoch, batch_size=batch_size, verbose=2, validation_data=(images_train, annotations_train), callbacks=[])\n","\n","# Save the model\n","model.save(model_file)\n","\n","\n","# Evaluate the model\n","score = model.evaluate(images_validation, annotations_validation, verbose=0)\n","print('Evaluating')\n","print('Test loss: ', score[0])\n","print('Test accuracy: ', score[1])\n","print('Test mean squared error: ', score[2])\n","print('Test mean absolute error: ', score[3])\n","\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyLpTduJdoA0"},"source":["import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","# Loss Curves\n","plt.figure(figsize=[8, 6])\n","plt.plot(model_history.history['loss'], 'r', linewidth=3.0)\n","plt.plot(model_history.history['val_loss'], 'b', linewidth=3.0)\n","plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n","plt.xlabel('Epochs ', fontsize=16)\n","plt.ylabel('Loss', fontsize=16)\n","plt.title('Loss Curves', fontsize=16)\n","plt.show()\n","\n","# Accuracy Curves\n","plt.figure(figsize=[8, 6])\n","plt.plot(model_history.history['accuracy'], 'r', linewidth=3.0)\n","plt.plot(model_history.history['val_accuracy'], 'b', linewidth=3.0)\n","plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n","plt.xlabel('Epochs ', fontsize=16)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.title('Accuracy Curves', fontsize=16)\n","plt.show()\n"],"execution_count":null,"outputs":[]}]}