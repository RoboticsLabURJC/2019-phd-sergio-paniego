{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BS_recurrent_pilotnet_2_networks.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPDOJYbYNpCrcBTZkdvMRVc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EGei9kb6bZwZ"},"source":["<a href=\"https://colab.research.google.com/github/RoboticsLabURJC/2019-phd-sergio-paniego/blob/main/behavior_studio_networks/BS_recurrent_pilotnet_2_networks.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"]},{"cell_type":"code","metadata":{"id":"pSXdSYABpKVz"},"source":["# When using Colab, check the GPU that is assigned and reload the runtime if its memory is low\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAsPdASw2ZqY"},"source":["# Mount Google Drive to access images dataset\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Yn9ltRs2cjx"},"source":["!ls \"/content/drive/My Drive\"\n","!ls \"/content/drive/My Drive/complete_dataset.zip\"\n","!unzip \"/content/drive/My Drive/curves_only.zip\"\n","!unzip \"/content/drive/My Drive/complete_dataset.zip\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZ2Mv4Xq8SAA"},"source":["from keras.models import Sequential\n","from keras.layers import Flatten, Dense, Conv2D, BatchNormalization, Dropout, ConvLSTM2D, Reshape, Activation, MaxPooling2D\n","from keras.layers import LSTM\n","from keras.layers.wrappers import TimeDistributed\n","from keras.optimizers import Adam\n","\n","\n","def pilotnet_model(img_shape):\n","    '''\n","    Model of End to End Learning for Self-Driving Cars (NVIDIA)\n","    '''\n","    model = Sequential()\n","    model.add(BatchNormalization(epsilon=0.001, axis=-1, input_shape=img_shape))\n","    model.add(Conv2D(24, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n","    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n","    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n","    model.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\",padding='same'))\n","    model.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\",padding='same'))\n","    model.add(Flatten())\n","    model.add(Dense(1164, activation=\"relu\"))\n","    model.add(Dense(100, activation=\"relu\"))\n","    model.add(Dense(50, activation=\"relu\"))\n","    model.add(Dense(10, activation=\"relu\"))\n","    model.add(Dense(1))\n","    adam = Adam(lr=0.0001)\n","    model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy', 'mse', 'mae'])\n","    return model\n","\n","\n","def tinypilotnet_model(img_shape):\n","    model = Sequential()\n","    model.add(BatchNormalization(epsilon=0.001, axis=-1, input_shape=img_shape))\n","    model.add(Conv2D(8, (3, 3), strides=(2, 2), activation=\"relu\"))\n","    model.add(Conv2D(8, (3, 3), strides=(2, 2), activation=\"relu\"))\n","    model.add(Dropout(0.5))\n","    model.add(Flatten())\n","    model.add(Dense(50, activation=\"relu\"))\n","    model.add(Dense(10, activation=\"relu\"))\n","    model.add(Dense(1))\n","    adam = Adam(lr=0.0001)\n","    model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy', 'mse', 'mae'])\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gs30irMcRbc3"},"source":["import glob\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","\n","def load_data(folder):\n","    name_folder = '/content/' + folder + '/Images/'\n","    list_images = glob.glob(name_folder + '*')\n","    print(list_images)\n","    images = sorted(list_images, key=lambda x: int(x.split('/')[4].split('.png')[0]))\n","    name_file = '/content/' + folder + '/data.json'\n","    file = open(name_file, 'r')\n","    data = file.read()\n","    file.close()\n","    return images, data\n","\n","def get_images(list_images, type_image, array_imgs):\n","    # Read the images\n","    for name in list_images:\n","        img = cv2.imread(name)\n","        if type_image == 'cropped':\n","            img = img[240:480, 0:640]\n","        img = cv2.resize(img, (int(img.shape[1] / 4), int(img.shape[0] / 4)))\n","        array_imgs.append(img)\n","\n","    return array_imgs\n","\n","def parse_json(data, array_v, array_w):\n","    # Process json\n","    data_parse = data.split('}')[:-1]\n","    for d in data_parse:\n","        v = d.split('\"v\": ')[1]\n","        d_parse = d.split(', \"v\":')[0]\n","        w = d_parse.split(('\"w\": '))[1]\n","        array_v.append(float(v))\n","        array_w.append(float(w))\n","\n","    return array_v, array_w\n","\n","def preprocess_data(array_w, array_v, imgs):\n","    # Take the image and just flip it and negate the measurement\n","    flip_imgs = []\n","    array_flip_w = []\n","    for i in range(len(array_w)):\n","        flip_imgs.append(cv2.flip(imgs[i], 1))\n","        array_flip_w.append(-array_w[i])\n","    new_array_w = array_w + array_flip_w\n","    new_array_v = array_v + array_v\n","    new_array_imgs = imgs + flip_imgs\n","    return new_array_w, new_array_v, new_array_imgs\n","\n","def add_extreme_data(array_w, imgs_w, array_v, imgs_v):\n","    for i in range(0, len(array_w)):\n","        if abs(array_w[i]) >= 1:\n","            if abs(array_w[i]) >= 2:\n","                num_iter = 10\n","            else:\n","                num_iter = 5\n","            for j in range(0, num_iter):\n","                array_w.append(array_w[i])\n","                imgs_w.append(imgs_w[i])\n","        if float(array_v[i]) <= 2:\n","            for j in range(0, 1):\n","                array_v.append(array_v[i])\n","                imgs_v.append(imgs_v[i])\n","    return array_w, imgs_w, array_v, imgs_v\n","\n","\n","# Load data\n","images, data = load_data('complete_dataset')\n","images_curve, data_curve = load_data('curves_only')\n","\n","# CHANGE type_image\n","type_image = 'cropped'\n","#type_image='normal'\n","\n","# Preprocess images\n","array_imgs = []\n","x = get_images(images, type_image, array_imgs)\n","x = get_images(images_curve, type_image, x)\n","# Preprocess json\n","array_v = []\n","array_w = []\n","y_v, y_w = parse_json(data, array_v, array_w)\n","y_v, y_w = parse_json(data_curve, y_v, y_w)\n","\n","\n","\n","if type_image == 'cropped':\n","    img_shape = (65, 160, 3)\n","else:\n","    img_shape = (120, 160, 3)\n","\n","# Adapt the data\n","y_w, y_v, x = preprocess_data(y_w, y_v, x)\n","x_w = x[:]\n","x_v = x[:]\n","y_w, x_w, y_v, x_v = add_extreme_data(y_w, x_w, y_v, x_v)\n","X_train_v, X_validation_v, y_train_v, y_validation_v = train_test_split(x_v, y_v, test_size=0.20, random_state=42)\n","X_train_w, X_validation_w, y_train_w, y_validation_w = train_test_split(x_w, y_w, test_size=0.20, random_state=42)\n","\n","\n","# Adapt the data\n","X_train_v = np.stack(X_train_v, axis=0)\n","y_train_v = np.stack(y_train_v, axis=0)\n","X_validation_v = np.stack(X_validation_v, axis=0)\n","y_validation_v = np.stack(y_validation_v, axis=0)\n","\n","X_train_w = np.stack(X_train_w, axis=0)\n","y_train_w = np.stack(y_train_w, axis=0)\n","X_validation_w = np.stack(X_validation_w, axis=0)\n","y_validation_w = np.stack(y_validation_w, axis=0)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIf4jK7HXbbd"},"source":["print(X_train_v[1].shape)\n","print(img_shape)\n","img_shape = (60, 160, 3)\n","print(img_shape)\n","\n","model_v = pilotnet_model(img_shape)\n","model_w = pilotnet_model(img_shape)\n","# model_v = tinypilotnet_model(img_shape)\n","# model_w = tinypilotnet_model(img_shape)\n","batch_size_v = 64  # 16\n","batch_size_w = 64\n","nb_epoch_v = 300  # 223\n","nb_epoch_w = 300  # 212\n","\n","if type_image == 'cropped':\n","    model_file_v = '/content/drive/My Drive/model_pilotnet_cropped_300_v.h5'\n","    model_file_w = '/content/drive/My Drive/model_pilotnet_cropped_300_w.h5'\n","else:\n","    model_file_v = '/content/drive/My Drive/model_pilotnet_v.h5'\n","    model_file_w = '/content/drive/My Drive/model_pilotnet_w.h5'\n","\n","# Print layers\n","print(model_v.summary())\n","\n","#  Train\n","model_history_v = model_v.fit(X_train_v, y_train_v, epochs=nb_epoch_v, batch_size=batch_size_v, verbose=2, validation_data=(X_validation_v, y_validation_v), callbacks=[])\n","# Save the model V\n","model_v.save(model_file_v)\n","\n","#  Train\n","model_history_w = model_w.fit(X_train_w, y_train_w, epochs=nb_epoch_w, batch_size=batch_size_w, verbose=2, validation_data=(X_validation_w, y_validation_w), callbacks=[])\n","# Save the model W\n","model_w.save(model_file_w)\n","\n","\n","# We evaluate the model\n","score = model_v.evaluate(X_validation_v, y_validation_v, verbose=0)\n","print('Evaluating v')\n","print('Test loss: ', score[0])\n","print('Test accuracy: ', score[1])\n","print('Test mean squared error: ', score[2])\n","print('Test mean absolute error: ', score[3])\n","\n","score = model_w.evaluate(X_validation_w, y_validation_w, verbose=0)\n","print('Evaluating w')\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","print('Test mean squared error: ', score[2])\n","print('Test mean absolute error: ', score[3])\n","\n"],"execution_count":null,"outputs":[]}]}